Freeze Vision Encoder:
https://github.com/microsoft/Swin-Transformer/blob/main/MODELHUB.md#imagenet-22k-pretrained-swin-moe-models

- Using SwinV2-S_16x16 Pretrain on ImageNet 1k: 50M Parameters
- Resources: https://colab.research.google.com/github/huggingface/notebooks/blob/main/examples/image_classification.ipynb
- https://huggingface.co/docs/transformers/en/model_doc/swinv2#transformers.Swinv2ForImageClassification

```
from transformers import AutoImageProcessor, Swinv2Model
import torch
from datasets import load_dataset

dataset = load_dataset("huggingface/cats-image")
image = dataset["test"]["image"][0]

image_processor = AutoImageProcessor.from_pretrained("microsoft/swinv2-tiny-patch4-window8-256")
model = Swinv2Model.from_pretrained("microsoft/swinv2-tiny-patch4-window8-256")

inputs = image_processor(image, return_tensors="pt")

with torch.no_grad():
    outputs = model(**inputs)

last_hidden_states = outputs.last_hidden_state
list(last_hidden_states.shape)
```
#wokule

Datasets:

Training Dataset:

CBIS-DDSM (Curated Breast Imaging Subset of DDSM) 
    https://www.cancerimagingarchive.net/collection/cbis-ddsm/

ISIC 2018 Dataset (https://drive.google.com/file/d/1lOo26YKisfC1vk22bNRvWjpnamS02bmL/view?usp=drive_link)
It already contains training set and test set:
Train: 10015 images and 1 ground truth response CSV file (containing 1 header row and 10015 corresponding response rows).
    https://challenge.isic-archive.com/data/#2018

Test: 1512 images.




PHG-Net Summary:

PHG train backbone (Swin-V2) init from image net for each dataset; 
we want to explore if freezeing the image encoder and adding information from topo encoder 
can yield comparable result.

Swin-V2:
Freeze then do linear_prob

Experiement Result Link: https://docs.google.com/spreadsheets/d/1UrvooZ4ID3i7AEw94iJYSRYg_aHv4j3iyCpkhRfu8UY/edit?usp=sharing

