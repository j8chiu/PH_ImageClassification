{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "fn = os.path.join('/Users/chiuchiu/Downloads/ISIC2018/label_test.csv')\n",
    "csvfile = pd.read_csv(fn)\n",
    "raw_data = csvfile.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([['ISIC_0034524', 0.0, 1.0, ..., 0.0, 0.0, 0.0],\n",
       "       ['ISIC_0034525', 0.0, 1.0, ..., 0.0, 0.0, 0.0],\n",
       "       ['ISIC_0034526', 0.0, 0.0, ..., 1.0, 0.0, 0.0],\n",
       "       ...,\n",
       "       ['ISIC_0036062', 0.0, 0.0, ..., 0.0, 0.0, 0.0],\n",
       "       ['ISIC_0036063', 0.0, 0.0, ..., 1.0, 0.0, 0.0],\n",
       "       ['ISIC_0036064', 0.0, 0.0, ..., 0.0, 0.0, 0.0]], dtype=object)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import transforms\n",
    "from dataset.isic_dataset import ISICDataset\n",
    "from torch.utils.data.dataloader import DataLoader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_path = '/Users/leo/Desktop/PH_ImageClassification/pre_trained_weights/swin_v2_b-781e5279.pth'\n",
    "checkpoint = torch.load(checkpoint_path,map_location = torch.device('cpu'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "449"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(checkpoint.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "delete features =================================\n"
     ]
    }
   ],
   "source": [
    "from models.swin_transformer_v2 import swin_v2_b\n",
    "net = swin_v2_b(weights=\"IMAGENET1K_V1\", num_classes=1000,).bfloat16()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SwinTransformer(\n",
       "  (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "  (permute): Permute()\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
       "  (head): Linear(in_features=1024, out_features=1000, bias=True)\n",
       "  (patch_embedding): Sequential(\n",
       "    (0): Conv2d(3, 128, kernel_size=(4, 4), stride=(4, 4))\n",
       "    (1): Permute()\n",
       "    (2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "  )\n",
       "  (stage_1): Sequential(\n",
       "    (0): SwinTransformerBlockV2(\n",
       "      (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "      (attn): ShiftedWindowAttentionV2(\n",
       "        (qkv): Linear(in_features=128, out_features=384, bias=True)\n",
       "        (proj): Linear(in_features=128, out_features=128, bias=True)\n",
       "        (cpb_mlp): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=512, bias=True)\n",
       "          (1): ReLU(inplace=True)\n",
       "          (2): Linear(in_features=512, out_features=4, bias=False)\n",
       "        )\n",
       "      )\n",
       "      (stochastic_depth): StochasticDepth(p=0.0, mode=row)\n",
       "      (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "      (mlp): MLP(\n",
       "        (0): Linear(in_features=128, out_features=512, bias=True)\n",
       "        (1): GELU(approximate='none')\n",
       "        (2): Dropout(p=0.0, inplace=False)\n",
       "        (3): Linear(in_features=512, out_features=128, bias=True)\n",
       "        (4): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "    )\n",
       "    (1): SwinTransformerBlockV2(\n",
       "      (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "      (attn): ShiftedWindowAttentionV2(\n",
       "        (qkv): Linear(in_features=128, out_features=384, bias=True)\n",
       "        (proj): Linear(in_features=128, out_features=128, bias=True)\n",
       "        (cpb_mlp): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=512, bias=True)\n",
       "          (1): ReLU(inplace=True)\n",
       "          (2): Linear(in_features=512, out_features=4, bias=False)\n",
       "        )\n",
       "      )\n",
       "      (stochastic_depth): StochasticDepth(p=0.021739130434782608, mode=row)\n",
       "      (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "      (mlp): MLP(\n",
       "        (0): Linear(in_features=128, out_features=512, bias=True)\n",
       "        (1): GELU(approximate='none')\n",
       "        (2): Dropout(p=0.0, inplace=False)\n",
       "        (3): Linear(in_features=512, out_features=128, bias=True)\n",
       "        (4): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (stage_2): Sequential(\n",
       "    (0): PatchMergingV2(\n",
       "      (reduction): Linear(in_features=512, out_features=256, bias=False)\n",
       "      (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "    (1): Sequential(\n",
       "      (0): SwinTransformerBlockV2(\n",
       "        (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): ShiftedWindowAttentionV2(\n",
       "          (qkv): Linear(in_features=256, out_features=768, bias=True)\n",
       "          (proj): Linear(in_features=256, out_features=256, bias=True)\n",
       "          (cpb_mlp): Sequential(\n",
       "            (0): Linear(in_features=2, out_features=512, bias=True)\n",
       "            (1): ReLU(inplace=True)\n",
       "            (2): Linear(in_features=512, out_features=8, bias=False)\n",
       "          )\n",
       "        )\n",
       "        (stochastic_depth): StochasticDepth(p=0.043478260869565216, mode=row)\n",
       "        (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): MLP(\n",
       "          (0): Linear(in_features=256, out_features=1024, bias=True)\n",
       "          (1): GELU(approximate='none')\n",
       "          (2): Dropout(p=0.0, inplace=False)\n",
       "          (3): Linear(in_features=1024, out_features=256, bias=True)\n",
       "          (4): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (1): SwinTransformerBlockV2(\n",
       "        (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): ShiftedWindowAttentionV2(\n",
       "          (qkv): Linear(in_features=256, out_features=768, bias=True)\n",
       "          (proj): Linear(in_features=256, out_features=256, bias=True)\n",
       "          (cpb_mlp): Sequential(\n",
       "            (0): Linear(in_features=2, out_features=512, bias=True)\n",
       "            (1): ReLU(inplace=True)\n",
       "            (2): Linear(in_features=512, out_features=8, bias=False)\n",
       "          )\n",
       "        )\n",
       "        (stochastic_depth): StochasticDepth(p=0.06521739130434782, mode=row)\n",
       "        (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): MLP(\n",
       "          (0): Linear(in_features=256, out_features=1024, bias=True)\n",
       "          (1): GELU(approximate='none')\n",
       "          (2): Dropout(p=0.0, inplace=False)\n",
       "          (3): Linear(in_features=1024, out_features=256, bias=True)\n",
       "          (4): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (stage_3): Sequential(\n",
       "    (0): PatchMergingV2(\n",
       "      (reduction): Linear(in_features=1024, out_features=512, bias=False)\n",
       "      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "    (1): Sequential(\n",
       "      (0): SwinTransformerBlockV2(\n",
       "        (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): ShiftedWindowAttentionV2(\n",
       "          (qkv): Linear(in_features=512, out_features=1536, bias=True)\n",
       "          (proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "          (cpb_mlp): Sequential(\n",
       "            (0): Linear(in_features=2, out_features=512, bias=True)\n",
       "            (1): ReLU(inplace=True)\n",
       "            (2): Linear(in_features=512, out_features=16, bias=False)\n",
       "          )\n",
       "        )\n",
       "        (stochastic_depth): StochasticDepth(p=0.08695652173913043, mode=row)\n",
       "        (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): MLP(\n",
       "          (0): Linear(in_features=512, out_features=2048, bias=True)\n",
       "          (1): GELU(approximate='none')\n",
       "          (2): Dropout(p=0.0, inplace=False)\n",
       "          (3): Linear(in_features=2048, out_features=512, bias=True)\n",
       "          (4): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (1): SwinTransformerBlockV2(\n",
       "        (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): ShiftedWindowAttentionV2(\n",
       "          (qkv): Linear(in_features=512, out_features=1536, bias=True)\n",
       "          (proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "          (cpb_mlp): Sequential(\n",
       "            (0): Linear(in_features=2, out_features=512, bias=True)\n",
       "            (1): ReLU(inplace=True)\n",
       "            (2): Linear(in_features=512, out_features=16, bias=False)\n",
       "          )\n",
       "        )\n",
       "        (stochastic_depth): StochasticDepth(p=0.10869565217391304, mode=row)\n",
       "        (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): MLP(\n",
       "          (0): Linear(in_features=512, out_features=2048, bias=True)\n",
       "          (1): GELU(approximate='none')\n",
       "          (2): Dropout(p=0.0, inplace=False)\n",
       "          (3): Linear(in_features=2048, out_features=512, bias=True)\n",
       "          (4): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (2): SwinTransformerBlockV2(\n",
       "        (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): ShiftedWindowAttentionV2(\n",
       "          (qkv): Linear(in_features=512, out_features=1536, bias=True)\n",
       "          (proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "          (cpb_mlp): Sequential(\n",
       "            (0): Linear(in_features=2, out_features=512, bias=True)\n",
       "            (1): ReLU(inplace=True)\n",
       "            (2): Linear(in_features=512, out_features=16, bias=False)\n",
       "          )\n",
       "        )\n",
       "        (stochastic_depth): StochasticDepth(p=0.13043478260869565, mode=row)\n",
       "        (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): MLP(\n",
       "          (0): Linear(in_features=512, out_features=2048, bias=True)\n",
       "          (1): GELU(approximate='none')\n",
       "          (2): Dropout(p=0.0, inplace=False)\n",
       "          (3): Linear(in_features=2048, out_features=512, bias=True)\n",
       "          (4): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (3): SwinTransformerBlockV2(\n",
       "        (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): ShiftedWindowAttentionV2(\n",
       "          (qkv): Linear(in_features=512, out_features=1536, bias=True)\n",
       "          (proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "          (cpb_mlp): Sequential(\n",
       "            (0): Linear(in_features=2, out_features=512, bias=True)\n",
       "            (1): ReLU(inplace=True)\n",
       "            (2): Linear(in_features=512, out_features=16, bias=False)\n",
       "          )\n",
       "        )\n",
       "        (stochastic_depth): StochasticDepth(p=0.15217391304347827, mode=row)\n",
       "        (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): MLP(\n",
       "          (0): Linear(in_features=512, out_features=2048, bias=True)\n",
       "          (1): GELU(approximate='none')\n",
       "          (2): Dropout(p=0.0, inplace=False)\n",
       "          (3): Linear(in_features=2048, out_features=512, bias=True)\n",
       "          (4): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (4): SwinTransformerBlockV2(\n",
       "        (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): ShiftedWindowAttentionV2(\n",
       "          (qkv): Linear(in_features=512, out_features=1536, bias=True)\n",
       "          (proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "          (cpb_mlp): Sequential(\n",
       "            (0): Linear(in_features=2, out_features=512, bias=True)\n",
       "            (1): ReLU(inplace=True)\n",
       "            (2): Linear(in_features=512, out_features=16, bias=False)\n",
       "          )\n",
       "        )\n",
       "        (stochastic_depth): StochasticDepth(p=0.17391304347826086, mode=row)\n",
       "        (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): MLP(\n",
       "          (0): Linear(in_features=512, out_features=2048, bias=True)\n",
       "          (1): GELU(approximate='none')\n",
       "          (2): Dropout(p=0.0, inplace=False)\n",
       "          (3): Linear(in_features=2048, out_features=512, bias=True)\n",
       "          (4): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (5): SwinTransformerBlockV2(\n",
       "        (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): ShiftedWindowAttentionV2(\n",
       "          (qkv): Linear(in_features=512, out_features=1536, bias=True)\n",
       "          (proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "          (cpb_mlp): Sequential(\n",
       "            (0): Linear(in_features=2, out_features=512, bias=True)\n",
       "            (1): ReLU(inplace=True)\n",
       "            (2): Linear(in_features=512, out_features=16, bias=False)\n",
       "          )\n",
       "        )\n",
       "        (stochastic_depth): StochasticDepth(p=0.1956521739130435, mode=row)\n",
       "        (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): MLP(\n",
       "          (0): Linear(in_features=512, out_features=2048, bias=True)\n",
       "          (1): GELU(approximate='none')\n",
       "          (2): Dropout(p=0.0, inplace=False)\n",
       "          (3): Linear(in_features=2048, out_features=512, bias=True)\n",
       "          (4): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (6): SwinTransformerBlockV2(\n",
       "        (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): ShiftedWindowAttentionV2(\n",
       "          (qkv): Linear(in_features=512, out_features=1536, bias=True)\n",
       "          (proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "          (cpb_mlp): Sequential(\n",
       "            (0): Linear(in_features=2, out_features=512, bias=True)\n",
       "            (1): ReLU(inplace=True)\n",
       "            (2): Linear(in_features=512, out_features=16, bias=False)\n",
       "          )\n",
       "        )\n",
       "        (stochastic_depth): StochasticDepth(p=0.21739130434782608, mode=row)\n",
       "        (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): MLP(\n",
       "          (0): Linear(in_features=512, out_features=2048, bias=True)\n",
       "          (1): GELU(approximate='none')\n",
       "          (2): Dropout(p=0.0, inplace=False)\n",
       "          (3): Linear(in_features=2048, out_features=512, bias=True)\n",
       "          (4): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (7): SwinTransformerBlockV2(\n",
       "        (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): ShiftedWindowAttentionV2(\n",
       "          (qkv): Linear(in_features=512, out_features=1536, bias=True)\n",
       "          (proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "          (cpb_mlp): Sequential(\n",
       "            (0): Linear(in_features=2, out_features=512, bias=True)\n",
       "            (1): ReLU(inplace=True)\n",
       "            (2): Linear(in_features=512, out_features=16, bias=False)\n",
       "          )\n",
       "        )\n",
       "        (stochastic_depth): StochasticDepth(p=0.2391304347826087, mode=row)\n",
       "        (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): MLP(\n",
       "          (0): Linear(in_features=512, out_features=2048, bias=True)\n",
       "          (1): GELU(approximate='none')\n",
       "          (2): Dropout(p=0.0, inplace=False)\n",
       "          (3): Linear(in_features=2048, out_features=512, bias=True)\n",
       "          (4): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (8): SwinTransformerBlockV2(\n",
       "        (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): ShiftedWindowAttentionV2(\n",
       "          (qkv): Linear(in_features=512, out_features=1536, bias=True)\n",
       "          (proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "          (cpb_mlp): Sequential(\n",
       "            (0): Linear(in_features=2, out_features=512, bias=True)\n",
       "            (1): ReLU(inplace=True)\n",
       "            (2): Linear(in_features=512, out_features=16, bias=False)\n",
       "          )\n",
       "        )\n",
       "        (stochastic_depth): StochasticDepth(p=0.2608695652173913, mode=row)\n",
       "        (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): MLP(\n",
       "          (0): Linear(in_features=512, out_features=2048, bias=True)\n",
       "          (1): GELU(approximate='none')\n",
       "          (2): Dropout(p=0.0, inplace=False)\n",
       "          (3): Linear(in_features=2048, out_features=512, bias=True)\n",
       "          (4): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (9): SwinTransformerBlockV2(\n",
       "        (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): ShiftedWindowAttentionV2(\n",
       "          (qkv): Linear(in_features=512, out_features=1536, bias=True)\n",
       "          (proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "          (cpb_mlp): Sequential(\n",
       "            (0): Linear(in_features=2, out_features=512, bias=True)\n",
       "            (1): ReLU(inplace=True)\n",
       "            (2): Linear(in_features=512, out_features=16, bias=False)\n",
       "          )\n",
       "        )\n",
       "        (stochastic_depth): StochasticDepth(p=0.2826086956521739, mode=row)\n",
       "        (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): MLP(\n",
       "          (0): Linear(in_features=512, out_features=2048, bias=True)\n",
       "          (1): GELU(approximate='none')\n",
       "          (2): Dropout(p=0.0, inplace=False)\n",
       "          (3): Linear(in_features=2048, out_features=512, bias=True)\n",
       "          (4): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (10): SwinTransformerBlockV2(\n",
       "        (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): ShiftedWindowAttentionV2(\n",
       "          (qkv): Linear(in_features=512, out_features=1536, bias=True)\n",
       "          (proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "          (cpb_mlp): Sequential(\n",
       "            (0): Linear(in_features=2, out_features=512, bias=True)\n",
       "            (1): ReLU(inplace=True)\n",
       "            (2): Linear(in_features=512, out_features=16, bias=False)\n",
       "          )\n",
       "        )\n",
       "        (stochastic_depth): StochasticDepth(p=0.30434782608695654, mode=row)\n",
       "        (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): MLP(\n",
       "          (0): Linear(in_features=512, out_features=2048, bias=True)\n",
       "          (1): GELU(approximate='none')\n",
       "          (2): Dropout(p=0.0, inplace=False)\n",
       "          (3): Linear(in_features=2048, out_features=512, bias=True)\n",
       "          (4): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (11): SwinTransformerBlockV2(\n",
       "        (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): ShiftedWindowAttentionV2(\n",
       "          (qkv): Linear(in_features=512, out_features=1536, bias=True)\n",
       "          (proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "          (cpb_mlp): Sequential(\n",
       "            (0): Linear(in_features=2, out_features=512, bias=True)\n",
       "            (1): ReLU(inplace=True)\n",
       "            (2): Linear(in_features=512, out_features=16, bias=False)\n",
       "          )\n",
       "        )\n",
       "        (stochastic_depth): StochasticDepth(p=0.32608695652173914, mode=row)\n",
       "        (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): MLP(\n",
       "          (0): Linear(in_features=512, out_features=2048, bias=True)\n",
       "          (1): GELU(approximate='none')\n",
       "          (2): Dropout(p=0.0, inplace=False)\n",
       "          (3): Linear(in_features=2048, out_features=512, bias=True)\n",
       "          (4): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (12): SwinTransformerBlockV2(\n",
       "        (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): ShiftedWindowAttentionV2(\n",
       "          (qkv): Linear(in_features=512, out_features=1536, bias=True)\n",
       "          (proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "          (cpb_mlp): Sequential(\n",
       "            (0): Linear(in_features=2, out_features=512, bias=True)\n",
       "            (1): ReLU(inplace=True)\n",
       "            (2): Linear(in_features=512, out_features=16, bias=False)\n",
       "          )\n",
       "        )\n",
       "        (stochastic_depth): StochasticDepth(p=0.34782608695652173, mode=row)\n",
       "        (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): MLP(\n",
       "          (0): Linear(in_features=512, out_features=2048, bias=True)\n",
       "          (1): GELU(approximate='none')\n",
       "          (2): Dropout(p=0.0, inplace=False)\n",
       "          (3): Linear(in_features=2048, out_features=512, bias=True)\n",
       "          (4): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (13): SwinTransformerBlockV2(\n",
       "        (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): ShiftedWindowAttentionV2(\n",
       "          (qkv): Linear(in_features=512, out_features=1536, bias=True)\n",
       "          (proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "          (cpb_mlp): Sequential(\n",
       "            (0): Linear(in_features=2, out_features=512, bias=True)\n",
       "            (1): ReLU(inplace=True)\n",
       "            (2): Linear(in_features=512, out_features=16, bias=False)\n",
       "          )\n",
       "        )\n",
       "        (stochastic_depth): StochasticDepth(p=0.3695652173913043, mode=row)\n",
       "        (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): MLP(\n",
       "          (0): Linear(in_features=512, out_features=2048, bias=True)\n",
       "          (1): GELU(approximate='none')\n",
       "          (2): Dropout(p=0.0, inplace=False)\n",
       "          (3): Linear(in_features=2048, out_features=512, bias=True)\n",
       "          (4): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (14): SwinTransformerBlockV2(\n",
       "        (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): ShiftedWindowAttentionV2(\n",
       "          (qkv): Linear(in_features=512, out_features=1536, bias=True)\n",
       "          (proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "          (cpb_mlp): Sequential(\n",
       "            (0): Linear(in_features=2, out_features=512, bias=True)\n",
       "            (1): ReLU(inplace=True)\n",
       "            (2): Linear(in_features=512, out_features=16, bias=False)\n",
       "          )\n",
       "        )\n",
       "        (stochastic_depth): StochasticDepth(p=0.391304347826087, mode=row)\n",
       "        (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): MLP(\n",
       "          (0): Linear(in_features=512, out_features=2048, bias=True)\n",
       "          (1): GELU(approximate='none')\n",
       "          (2): Dropout(p=0.0, inplace=False)\n",
       "          (3): Linear(in_features=2048, out_features=512, bias=True)\n",
       "          (4): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (15): SwinTransformerBlockV2(\n",
       "        (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): ShiftedWindowAttentionV2(\n",
       "          (qkv): Linear(in_features=512, out_features=1536, bias=True)\n",
       "          (proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "          (cpb_mlp): Sequential(\n",
       "            (0): Linear(in_features=2, out_features=512, bias=True)\n",
       "            (1): ReLU(inplace=True)\n",
       "            (2): Linear(in_features=512, out_features=16, bias=False)\n",
       "          )\n",
       "        )\n",
       "        (stochastic_depth): StochasticDepth(p=0.41304347826086957, mode=row)\n",
       "        (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): MLP(\n",
       "          (0): Linear(in_features=512, out_features=2048, bias=True)\n",
       "          (1): GELU(approximate='none')\n",
       "          (2): Dropout(p=0.0, inplace=False)\n",
       "          (3): Linear(in_features=2048, out_features=512, bias=True)\n",
       "          (4): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (16): SwinTransformerBlockV2(\n",
       "        (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): ShiftedWindowAttentionV2(\n",
       "          (qkv): Linear(in_features=512, out_features=1536, bias=True)\n",
       "          (proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "          (cpb_mlp): Sequential(\n",
       "            (0): Linear(in_features=2, out_features=512, bias=True)\n",
       "            (1): ReLU(inplace=True)\n",
       "            (2): Linear(in_features=512, out_features=16, bias=False)\n",
       "          )\n",
       "        )\n",
       "        (stochastic_depth): StochasticDepth(p=0.43478260869565216, mode=row)\n",
       "        (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): MLP(\n",
       "          (0): Linear(in_features=512, out_features=2048, bias=True)\n",
       "          (1): GELU(approximate='none')\n",
       "          (2): Dropout(p=0.0, inplace=False)\n",
       "          (3): Linear(in_features=2048, out_features=512, bias=True)\n",
       "          (4): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (17): SwinTransformerBlockV2(\n",
       "        (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): ShiftedWindowAttentionV2(\n",
       "          (qkv): Linear(in_features=512, out_features=1536, bias=True)\n",
       "          (proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "          (cpb_mlp): Sequential(\n",
       "            (0): Linear(in_features=2, out_features=512, bias=True)\n",
       "            (1): ReLU(inplace=True)\n",
       "            (2): Linear(in_features=512, out_features=16, bias=False)\n",
       "          )\n",
       "        )\n",
       "        (stochastic_depth): StochasticDepth(p=0.45652173913043476, mode=row)\n",
       "        (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): MLP(\n",
       "          (0): Linear(in_features=512, out_features=2048, bias=True)\n",
       "          (1): GELU(approximate='none')\n",
       "          (2): Dropout(p=0.0, inplace=False)\n",
       "          (3): Linear(in_features=2048, out_features=512, bias=True)\n",
       "          (4): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (stage_4): Sequential(\n",
       "    (0): PatchMergingV2(\n",
       "      (reduction): Linear(in_features=2048, out_features=1024, bias=False)\n",
       "      (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "    (1): Sequential(\n",
       "      (0): SwinTransformerBlockV2(\n",
       "        (norm1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): ShiftedWindowAttentionV2(\n",
       "          (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "          (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (cpb_mlp): Sequential(\n",
       "            (0): Linear(in_features=2, out_features=512, bias=True)\n",
       "            (1): ReLU(inplace=True)\n",
       "            (2): Linear(in_features=512, out_features=32, bias=False)\n",
       "          )\n",
       "        )\n",
       "        (stochastic_depth): StochasticDepth(p=0.4782608695652174, mode=row)\n",
       "        (norm2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): MLP(\n",
       "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (1): GELU(approximate='none')\n",
       "          (2): Dropout(p=0.0, inplace=False)\n",
       "          (3): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (4): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (1): SwinTransformerBlockV2(\n",
       "        (norm1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): ShiftedWindowAttentionV2(\n",
       "          (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "          (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (cpb_mlp): Sequential(\n",
       "            (0): Linear(in_features=2, out_features=512, bias=True)\n",
       "            (1): ReLU(inplace=True)\n",
       "            (2): Linear(in_features=512, out_features=32, bias=False)\n",
       "          )\n",
       "        )\n",
       "        (stochastic_depth): StochasticDepth(p=0.5, mode=row)\n",
       "        (norm2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): MLP(\n",
       "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (1): GELU(approximate='none')\n",
       "          (2): Dropout(p=0.0, inplace=False)\n",
       "          (3): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (4): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_transform = transforms.Compose([\n",
    "    transforms.ToTensor(),])\n",
    "\n",
    "data = ISICDataset(transform=train_transform)\n",
    "dataloader = DataLoader(data, batch_size=4)\n",
    "for image,target in dataloader:\n",
    "    image = image.bfloat16()\n",
    "    pred,_ = net(image)\n",
    "    print(pred.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.io import read_image\n",
    "img = read_image('/Users/leo/Desktop/PH_ImageClassification/data/raw_data/ISIC2018/train/ISIC_0024306.jpg')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#BH1(C/H) @ BH(C/H)N -> BH1N\n",
    "B = 20\n",
    "H = 12\n",
    "C = 768\n",
    "N = 256\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([20, 12, 1, 64])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = torch.randn(B,H,1,C//H)\n",
    "a.shape\n",
    "\n",
    "b = torch.randn(B,H,C//H,N)\n",
    "b.shape\n",
    "\n",
    "d = b@a\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([20, 12, 64, 256])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b = torch.randn(B,H,C//H,N)\n",
    "b.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([20, 12, 1, 256])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c = a @ b\n",
    "c.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Expected size for first two dimensions of batch2 tensor to be: [240, 256] but got: [240, 64].",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m b\u001b[38;5;129m@a\u001b[39m\u001b[38;5;241m.\u001b[39mtranspose(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Expected size for first two dimensions of batch2 tensor to be: [240, 256] but got: [240, 64]."
     ]
    }
   ],
   "source": [
    "b@a.transpose(-2, -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PHG_cross_attn import CrossAttention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "B = 20\n",
    "H = 12\n",
    "C = 768\n",
    "N = 256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "q = torch.randn(B,N,C).bfloat16()\n",
    "kv = torch.randn(B,1,C).bfloat16()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([20, 256, 768])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([20, 1, 768])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kv.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "attn shape torch.Size([20, 12, 256, 1])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([20, 256, 768])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = CrossAttention(dim=768,num_heads=12)\n",
    "o = model(q=q,kv=kv,mask=None) #attn: B,H,N,1\n",
    "o.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'diagram': [array([[0.00000000e+00, 7.84295253e-07, 1.00000000e+00, 0.00000000e+00],\n",
       "         [0.00000000e+00, 7.84312988e-07, 1.00000000e+00, 0.00000000e+00],\n",
       "         [0.00000000e+00, 7.84330666e-07, 1.00000000e+00, 0.00000000e+00],\n",
       "         ...,\n",
       "         [0.00000000e+00, 2.49054898e-02, 1.00000000e+00, 0.00000000e+00],\n",
       "         [0.00000000e+00, 7.66360760e-02, 1.00000000e+00, 0.00000000e+00],\n",
       "         [0.00000000e+00,            inf, 1.00000000e+00, 0.00000000e+00]]),\n",
       "  array([], shape=(0, 4), dtype=float64)],\n",
       " 'landscape': array([[0.94698494, 0.17153489, 0.55950997, 0.54248926, 0.70245996,\n",
       "         0.80731164, 0.21960484, 0.83751621, 0.30931023, 0.29386811,\n",
       "         0.35947401, 0.2635745 , 0.16943753, 0.90368972, 0.04456185,\n",
       "         0.71057978, 0.66419823, 0.81466073, 0.59600281, 0.22349145,\n",
       "         0.33561491, 0.72599646, 0.06463831, 0.64128233, 0.28279385,\n",
       "         0.33012118, 0.3409084 , 0.27613594, 0.72998602, 0.39729563,\n",
       "         0.91391164, 0.64982729, 0.82921205, 0.15144727, 0.29131637,\n",
       "         0.78720925, 0.50518112, 0.22518657, 0.67937624, 0.27712048,\n",
       "         0.05387534, 0.76289986, 0.37805719, 0.04200476, 0.34615818,\n",
       "         0.03194331, 0.57602967, 0.48853732, 0.98549894, 0.67651334,\n",
       "         0.05081163, 0.16964632, 0.38928056, 0.88889154, 0.50539273,\n",
       "         0.93941346, 0.68238035, 0.87358641, 0.528725  , 0.92658125,\n",
       "         0.02787594, 0.1641383 , 0.33096703, 0.26661263, 0.29631952,\n",
       "         0.26677923, 0.28222897, 0.45873531, 0.72920167, 0.69984267,\n",
       "         0.91008628, 0.27851052, 0.4017216 , 0.92174411, 0.40201408,\n",
       "         0.56704379, 0.85677226, 0.82066139, 0.79631775, 0.04483115,\n",
       "         0.9230885 , 0.9715864 , 0.50438944, 0.51429856, 0.07949429,\n",
       "         0.88679273, 0.53816129, 0.86009353, 0.69799965, 0.78435103,\n",
       "         0.4694459 , 0.21698317, 0.81024922, 0.00569881, 0.17718971,\n",
       "         0.37846314, 0.86188281, 0.11423687, 0.91641352, 0.68158107],\n",
       "        [0.52055384, 0.20374913, 0.69233301, 0.28318739, 0.44531135,\n",
       "         0.8783847 , 0.81708828, 0.58223289, 0.99478779, 0.40553013,\n",
       "         0.14869875, 0.65536305, 0.67196358, 0.86074315, 0.28472988,\n",
       "         0.67684362, 0.1531083 , 0.98182376, 0.27085125, 0.87691264,\n",
       "         0.92364652, 0.69605499, 0.52741107, 0.4137669 , 0.64343695,\n",
       "         0.49331128, 0.62011875, 0.05949877, 0.10117212, 0.59402543,\n",
       "         0.79456535, 0.17534477, 0.21787191, 0.81192334, 0.23539291,\n",
       "         0.88200168, 0.47501525, 0.44429738, 0.91891914, 0.3969512 ,\n",
       "         0.1586645 , 0.52508271, 0.98163945, 0.69903577, 0.20716746,\n",
       "         0.64596627, 0.20408168, 0.46846642, 0.71163957, 0.49250169,\n",
       "         0.26734791, 0.75791952, 0.96506649, 0.70852755, 0.80989883,\n",
       "         0.41628556, 0.34829553, 0.54534596, 0.17067972, 0.18972552,\n",
       "         0.16727591, 0.33023426, 0.96590664, 0.86264443, 0.51652097,\n",
       "         0.45558715, 0.20934502, 0.79000205, 0.84297815, 0.94143834,\n",
       "         0.00854775, 0.65709548, 0.47412996, 0.99384848, 0.5021167 ,\n",
       "         0.16812757, 0.57341411, 0.0518323 , 0.14370613, 0.10543759,\n",
       "         0.57222707, 0.66366496, 0.83951768, 0.55648766, 0.12885063,\n",
       "         0.51373503, 0.6544022 , 0.20810447, 0.98322006, 0.15239895,\n",
       "         0.86206935, 0.14758521, 0.92386948, 0.72132354, 0.45482079,\n",
       "         0.32652341, 0.64745372, 0.90236916, 0.10194593, 0.80184063],\n",
       "        [0.84359177, 0.33680739, 0.38872919, 0.21722218, 0.98154864,\n",
       "         0.70508228, 0.87220113, 0.42257202, 0.54742936, 0.7827982 ,\n",
       "         0.46179441, 0.80228016, 0.01179985, 0.40047548, 0.04573516,\n",
       "         0.73324719, 0.8193868 , 0.30779997, 0.90051015, 0.05038098,\n",
       "         0.65880562, 0.2581154 , 0.93959123, 0.8221805 , 0.31671202,\n",
       "         0.2246195 , 0.81243772, 0.81067333, 0.32094074, 0.61527996,\n",
       "         0.74496844, 0.78401731, 0.56076937, 0.80323057, 0.90073466,\n",
       "         0.78349761, 0.01642082, 0.82837441, 0.54227414, 0.4699967 ,\n",
       "         0.55078711, 0.95251585, 0.08877905, 0.96118453, 0.98413883,\n",
       "         0.12686347, 0.48684886, 0.8284649 , 0.91923657, 0.13226718,\n",
       "         0.98811314, 0.0270368 , 0.03209989, 0.3524645 , 0.87833007,\n",
       "         0.47801563, 0.04747178, 0.12281632, 0.64724463, 0.58064439,\n",
       "         0.68113738, 0.5287887 , 0.19047553, 0.13144541, 0.94612522,\n",
       "         0.24086955, 0.25267133, 0.02271012, 0.73887923, 0.86455019,\n",
       "         0.44338449, 0.82953073, 0.22993628, 0.478015  , 0.23367406,\n",
       "         0.69635528, 0.17596501, 0.74507858, 0.72758515, 0.36539779,\n",
       "         0.5600647 , 0.94597482, 0.88769435, 0.0969757 , 0.62015651,\n",
       "         0.38187001, 0.433284  , 0.44178442, 0.01916453, 0.14886672,\n",
       "         0.1852004 , 0.26244079, 0.85727187, 0.319849  , 0.21338313,\n",
       "         0.17012154, 0.62215204, 0.92579114, 0.32057762, 0.12556217],\n",
       "        [0.12997617, 0.17990377, 0.7082623 , 0.25649561, 0.36028832,\n",
       "         0.88043227, 0.14999638, 0.19326177, 0.84868454, 0.40836906,\n",
       "         0.04062094, 0.45737528, 0.15416849, 0.00462333, 0.75449725,\n",
       "         0.15352034, 0.15273215, 0.98432842, 0.48329807, 0.13488986,\n",
       "         0.80563149, 0.74768104, 0.70655416, 0.57429723, 0.47202668,\n",
       "         0.42869127, 0.20610584, 0.02397949, 0.66338839, 0.55516213,\n",
       "         0.21865026, 0.72516825, 0.82694876, 0.57531134, 0.34244999,\n",
       "         0.78752426, 0.35347875, 0.07854999, 0.74308736, 0.02612358,\n",
       "         0.46400177, 0.81026682, 0.09865131, 0.25051801, 0.51548609,\n",
       "         0.26358785, 0.79200035, 0.18807555, 0.0370477 , 0.97801677,\n",
       "         0.94879981, 0.46836091, 0.38369659, 0.41261024, 0.24920992,\n",
       "         0.97831625, 0.84289758, 0.84773371, 0.73331624, 0.94913828,\n",
       "         0.60640384, 0.51437976, 0.73605682, 0.7848967 , 0.47131313,\n",
       "         0.50904268, 0.87754237, 0.81113517, 0.52280811, 0.01084868,\n",
       "         0.09913449, 0.38153781, 0.36499701, 0.86147237, 0.11527153,\n",
       "         0.8983681 , 0.43934432, 0.45253901, 0.16477512, 0.21670625,\n",
       "         0.29652616, 0.68224096, 0.47514263, 0.87865985, 0.46389282,\n",
       "         0.86597842, 0.63262703, 0.67397056, 0.02529795, 0.17038843,\n",
       "         0.6726498 , 0.31159446, 0.56605109, 0.2739143 , 0.92135136,\n",
       "         0.94662833, 0.48465414, 0.73890064, 0.49882504, 0.58166116],\n",
       "        [0.16791138, 0.59506659, 0.59201169, 0.90918993, 0.60800228,\n",
       "         0.50508646, 0.38884199, 0.74881328, 0.52493112, 0.9661825 ,\n",
       "         0.13968642, 0.11371174, 0.71682893, 0.10655053, 0.40152564,\n",
       "         0.20149675, 0.50409026, 0.10924393, 0.99736632, 0.82259963,\n",
       "         0.0653642 , 0.49680994, 0.07498755, 0.17331168, 0.59451002,\n",
       "         0.4441143 , 0.08535188, 0.73598133, 0.86377377, 0.9189899 ,\n",
       "         0.56206149, 0.34966053, 0.10157356, 0.52675767, 0.33493427,\n",
       "         0.35996713, 0.15764301, 0.38580438, 0.00667658, 0.06461608,\n",
       "         0.70446529, 0.86678609, 0.45197603, 0.63042927, 0.54116596,\n",
       "         0.97073318, 0.20691147, 0.62053285, 0.79822382, 0.41269981,\n",
       "         0.42492961, 0.7161029 , 0.62552852, 0.02934126, 0.15708504,\n",
       "         0.05518306, 0.38868281, 0.07396491, 0.99791186, 0.52757851,\n",
       "         0.4515378 , 0.56746156, 0.02871964, 0.7809031 , 0.99717144,\n",
       "         0.60691568, 0.2781137 , 0.80080099, 0.83663113, 0.49597436,\n",
       "         0.36230442, 0.50058558, 0.30968298, 0.07479943, 0.36731502,\n",
       "         0.6877889 , 0.26498481, 0.52270526, 0.47752156, 0.78664121,\n",
       "         0.37775893, 0.79952004, 0.44147255, 0.65444408, 0.87715121,\n",
       "         0.35132784, 0.31348832, 0.93274496, 0.99423744, 0.8608303 ,\n",
       "         0.21984502, 0.39294478, 0.16629232, 0.06922497, 0.48906786,\n",
       "         0.10992942, 0.00926035, 0.66714246, 0.48845879, 0.56359345],\n",
       "        [0.18405862, 0.80559596, 0.4708843 , 0.05213912, 0.00423264,\n",
       "         0.34243284, 0.23839868, 0.23048997, 0.4467471 , 0.85435777,\n",
       "         0.38405192, 0.630924  , 0.59145913, 0.87690521, 0.4865051 ,\n",
       "         0.50789942, 0.15534917, 0.44174704, 0.37869153, 0.81412467,\n",
       "         0.08200988, 0.26902518, 0.92994757, 0.55453262, 0.52845091,\n",
       "         0.76403903, 0.11300175, 0.60588398, 0.17595925, 0.69065411,\n",
       "         0.21244639, 0.97010455, 0.78183331, 0.50380478, 0.96518279,\n",
       "         0.00723065, 0.64350336, 0.66641077, 0.43010628, 0.44153169,\n",
       "         0.4773452 , 0.41024391, 0.86184185, 0.32539906, 0.62766947,\n",
       "         0.15156674, 0.01561758, 0.06295336, 0.77656611, 0.543578  ,\n",
       "         0.38049337, 0.45051262, 0.64067836, 0.10833972, 0.58211238,\n",
       "         0.60736359, 0.23633022, 0.7504867 , 0.56948648, 0.60967398,\n",
       "         0.28439496, 0.90844467, 0.67493234, 0.0158362 , 0.95207191,\n",
       "         0.20550396, 0.83290127, 0.85119087, 0.68780732, 0.14145539,\n",
       "         0.36212277, 0.91106903, 0.19754443, 0.44804031, 0.04438318,\n",
       "         0.60900442, 0.67988398, 0.11617996, 0.70718775, 0.06809102,\n",
       "         0.60506374, 0.97820118, 0.71831941, 0.53740924, 0.57850349,\n",
       "         0.00115624, 0.5818936 , 0.2269713 , 0.53741529, 0.80550434,\n",
       "         0.11924484, 0.65725446, 0.12320634, 0.9187514 , 0.25866053,\n",
       "         0.51541796, 0.80911142, 0.08392616, 0.26187717, 0.11369412],\n",
       "        [0.78812198, 0.98607967, 0.80801969, 0.5982995 , 0.01297945,\n",
       "         0.85731932, 0.32473691, 0.13046033, 0.17846481, 0.04102588,\n",
       "         0.20179718, 0.80125906, 0.78043469, 0.27186423, 0.73096064,\n",
       "         0.34269142, 0.75344336, 0.55825197, 0.26471608, 0.4812112 ,\n",
       "         0.95750893, 0.51618619, 0.83567734, 0.76312278, 0.70953321,\n",
       "         0.87379636, 0.72244722, 0.38769443, 0.29389322, 0.77383568,\n",
       "         0.70257906, 0.99220642, 0.00707246, 0.16974473, 0.97244756,\n",
       "         0.33727314, 0.14752634, 0.90535126, 0.55421641, 0.44234249,\n",
       "         0.00962183, 0.75542817, 0.30835167, 0.68745234, 0.57903957,\n",
       "         0.90387211, 0.31420153, 0.92689201, 0.48118385, 0.52340295,\n",
       "         0.50997905, 0.83622507, 0.72014728, 0.63489086, 0.06353659,\n",
       "         0.03669619, 0.87746708, 0.91999738, 0.17403026, 0.4277967 ,\n",
       "         0.18485288, 0.14162809, 0.41952947, 0.80320499, 0.68062475,\n",
       "         0.43432715, 0.40235176, 0.80047427, 0.84921637, 0.38167312,\n",
       "         0.75865456, 0.29539656, 0.67966203, 0.19223906, 0.19172922,\n",
       "         0.59868694, 0.34701063, 0.59367502, 0.92507742, 0.91185595,\n",
       "         0.25684936, 0.1019482 , 0.74355079, 0.01276474, 0.90263804,\n",
       "         0.00831611, 0.61081469, 0.33277688, 0.73131189, 0.26007671,\n",
       "         0.09774108, 0.35483035, 0.80198631, 0.36160146, 0.09777668,\n",
       "         0.09272004, 0.59160621, 0.32950427, 0.0806679 , 0.29306728],\n",
       "        [0.32152482, 0.79983101, 0.95147242, 0.14065011, 0.4580732 ,\n",
       "         0.01710502, 0.44715103, 0.01549492, 0.50981754, 0.24939582,\n",
       "         0.82623903, 0.74632233, 0.63107201, 0.57022255, 0.03166054,\n",
       "         0.01558882, 0.28219128, 0.9404509 , 0.05115352, 0.72552897,\n",
       "         0.84624052, 0.14153779, 0.46497862, 0.49725656, 0.83949132,\n",
       "         0.79029331, 0.15195004, 0.93040781, 0.35600817, 0.31882419,\n",
       "         0.33659716, 0.68402142, 0.5824349 , 0.3980975 , 0.8399602 ,\n",
       "         0.90386707, 0.60200527, 0.27035467, 0.62013287, 0.28961533,\n",
       "         0.13624369, 0.72805156, 0.26408893, 0.70309071, 0.92115133,\n",
       "         0.96227393, 0.58537399, 0.19834634, 0.9697229 , 0.82382613,\n",
       "         0.92767771, 0.8626609 , 0.29564659, 0.6172478 , 0.90637882,\n",
       "         0.35681527, 0.43909112, 0.28873936, 0.62462915, 0.58612451,\n",
       "         0.60822092, 0.80894349, 0.82829847, 0.66682633, 0.65801714,\n",
       "         0.18982878, 0.81346965, 0.28019321, 0.99014452, 0.9468396 ,\n",
       "         0.43795418, 0.72076396, 0.88517402, 0.99433609, 0.57855003,\n",
       "         0.35455119, 0.88928586, 0.53404318, 0.68239292, 0.21605523,\n",
       "         0.88009165, 0.86090765, 0.79022983, 0.56143166, 0.42340135,\n",
       "         0.79997912, 0.27503812, 0.16275668, 0.06321299, 0.47685773,\n",
       "         0.98038606, 0.58474332, 0.07483903, 0.80587067, 0.47015183,\n",
       "         0.26816125, 0.55352719, 0.11312843, 0.22630556, 0.63706182],\n",
       "        [0.99974505, 0.03731569, 0.54456853, 0.01016666, 0.87674561,\n",
       "         0.24585069, 0.1619117 , 0.00748232, 0.44766805, 0.53816107,\n",
       "         0.26833119, 0.75117149, 0.99285998, 0.21808142, 0.03724434,\n",
       "         0.39487615, 0.78588413, 0.84290182, 0.10518264, 0.7154411 ,\n",
       "         0.74575014, 0.01491215, 0.40313425, 0.78016068, 0.49963678,\n",
       "         0.43166776, 0.3757349 , 0.12862107, 0.17672731, 0.08129727,\n",
       "         0.59554092, 0.39919757, 0.36943247, 0.5301706 , 0.34239994,\n",
       "         0.07705364, 0.59147973, 0.24053421, 0.91845719, 0.02305114,\n",
       "         0.93068585, 0.81307651, 0.24720213, 0.88266191, 0.88612724,\n",
       "         0.65031823, 0.43196754, 0.26997618, 0.42600793, 0.27201666,\n",
       "         0.75765417, 0.95134717, 0.10391739, 0.09537488, 0.98161777,\n",
       "         0.72204393, 0.91320035, 0.53954028, 0.57748   , 0.81595519,\n",
       "         0.44551817, 0.05463238, 0.58987483, 0.3413624 , 0.19953412,\n",
       "         0.55179937, 0.69584947, 0.65580885, 0.12576006, 0.23841341,\n",
       "         0.60636515, 0.12157925, 0.52327936, 0.83728433, 0.8639448 ,\n",
       "         0.48654412, 0.80444227, 0.31833005, 0.04880785, 0.58009016,\n",
       "         0.86908393, 0.65087358, 0.71773938, 0.54302135, 0.83869625,\n",
       "         0.65915092, 0.43260737, 0.45261146, 0.51793204, 0.23061542,\n",
       "         0.95417939, 0.18170578, 0.32766736, 0.91623412, 0.84720506,\n",
       "         0.70027049, 0.19489402, 0.26920347, 0.31332089, 0.12122317],\n",
       "        [0.69045076, 0.41776928, 0.15222612, 0.55689704, 0.75215294,\n",
       "         0.67535346, 0.16807562, 0.68352836, 0.52483231, 0.49912396,\n",
       "         0.50340808, 0.18411809, 0.2467776 , 0.42496452, 0.58243401,\n",
       "         0.72936425, 0.34587162, 0.16594872, 0.81919953, 0.41896183,\n",
       "         0.39198822, 0.72964648, 0.33696203, 0.16393652, 0.22099645,\n",
       "         0.92001537, 0.50141483, 0.68000395, 0.34809597, 0.42270375,\n",
       "         0.21710389, 0.8266781 , 0.13954574, 0.94033563, 0.64067346,\n",
       "         0.42290071, 0.13680065, 0.86418645, 0.48031325, 0.9137142 ,\n",
       "         0.71501088, 0.96660295, 0.840002  , 0.82329913, 0.79312507,\n",
       "         0.60221777, 0.38590847, 0.18905519, 0.08648132, 0.5475832 ,\n",
       "         0.11009361, 0.83961637, 0.650978  , 0.49902626, 0.51680457,\n",
       "         0.62117446, 0.67685694, 0.45759637, 0.59466587, 0.88210355,\n",
       "         0.88981214, 0.76415366, 0.25247566, 0.05931205, 0.61134251,\n",
       "         0.55530705, 0.59637044, 0.72165746, 0.90876159, 0.89875201,\n",
       "         0.31054366, 0.90055742, 0.36470305, 0.23608479, 0.99386768,\n",
       "         0.1621758 , 0.388944  , 0.03906856, 0.26982986, 0.96823589,\n",
       "         0.33234084, 0.50244949, 0.23489169, 0.84595436, 0.93832339,\n",
       "         0.30448679, 0.36653922, 0.37835322, 0.6575627 , 0.95648183,\n",
       "         0.86219082, 0.27073295, 0.89976268, 0.38461072, 0.93594434,\n",
       "         0.71206822, 0.14121502, 0.63708811, 0.83896969, 0.96301855]]),\n",
       " 'label': {'MEL': 0.0,\n",
       "  'NV': 1.0,\n",
       "  'BCC': 0.0,\n",
       "  'AKIEC': 0.0,\n",
       "  'BKL': 0.0,\n",
       "  'DF': 0.0,\n",
       "  'VASC': 0.0},\n",
       " 'image_path': 'data/raw_data/ISIC2018/train/ISIC_0024391.jpg'}"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_dict = np.load('data/raw_data/ISIC2018/train_ph/ISIC_0024391.npy',allow_pickle=True).item()\n",
    "data_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['diagram', 'landscape', 'label', 'image_path'])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_dict.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[0.00000000e+00, 7.84295253e-07, 1.00000000e+00, 0.00000000e+00],\n",
       "        [0.00000000e+00, 7.84312988e-07, 1.00000000e+00, 0.00000000e+00],\n",
       "        [0.00000000e+00, 7.84330666e-07, 1.00000000e+00, 0.00000000e+00],\n",
       "        ...,\n",
       "        [0.00000000e+00, 2.49054898e-02, 1.00000000e+00, 0.00000000e+00],\n",
       "        [0.00000000e+00, 7.66360760e-02, 1.00000000e+00, 0.00000000e+00],\n",
       "        [0.00000000e+00,            inf, 1.00000000e+00, 0.00000000e+00]]),\n",
       " array([], shape=(0, 4), dtype=float64)]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_dict['diagram']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data_dict['diagram'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(867, 4)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_dict['diagram'][0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[0.00000000e+00, 7.84295253e-07, 1.00000000e+00, 0.00000000e+00],\n",
       "        [0.00000000e+00, 7.84312988e-07, 1.00000000e+00, 0.00000000e+00],\n",
       "        [0.00000000e+00, 7.84330666e-07, 1.00000000e+00, 0.00000000e+00],\n",
       "        ...,\n",
       "        [0.00000000e+00, 2.49054898e-02, 1.00000000e+00, 0.00000000e+00],\n",
       "        [0.00000000e+00, 7.66360760e-02, 1.00000000e+00, 0.00000000e+00],\n",
       "        [0.00000000e+00,            inf, 1.00000000e+00, 0.00000000e+00]]),\n",
       " array([], shape=(0, 4), dtype=float64)]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_dict['diagram']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['diagram', 'landscape', 'label', 'image_path'])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_dict.keys()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
